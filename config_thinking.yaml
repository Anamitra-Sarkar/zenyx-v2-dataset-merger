# Config for THINKING / CoT / R1-style merge

output:
  repo_id: "Arko007/zenyx-v2-think"   # HF dataset repo to push to
  local_dir: "./out_thinking"
  private: true
  push_to_hf: false   # set true when ready to push

runtime:
  streaming: true
  # num_proc is defined here for reference but is NOT used by the pipeline.
  # Parallelism is handled at the upload stage (--upload-workers flag) only.
  num_proc: 4
  shard_size: 5000        # lowered for memory safety — CoT traces are large
  max_examples_per_dataset: null   # set e.g. 100 for a quick test run

schema:
  text_key_candidates:
    - "text"
    - "content"
    - "prompt"
    - "response"
    - "messages"
    - "conversations"
    - "conversation"
    - "completion"
    - "instruction"
    - "input"
    - "output"
    - "question"
    - "answer"
    - "solution"
    - "rationale"
    - "reasoning"
    - "cot"
    - "final"
    - "problem"
    - "chat"

datasets:
  # ── Math CoT ────────────────────────────────────────────────────
  - id: "PrimeIntellect/NuminaMath-QwQ-CoT-5M"
    subset: null
    split: "train"
  - id: "AI-MO/NuminaMath-CoT"
    subset: null
    split: "train"
  - id: "AI-MO/NuminaMath-TIR"
    subset: null
    split: "train"
  - id: "open-r1/OpenR1-Math-220k"
    subset: null
    split: "train"
  - id: "meta-math/MetaMathQA"
    subset: null
    split: "train"
  - id: "TIGER-Lab/MATH-plus"
    subset: null
    split: "train"
  - id: "169Pi/mathreasoning"
    subset: null
    split: "train"
  - id: "zwhe99/DeepMath-103K"
    subset: null
    split: "train"
  - id: "friendshipkim/DeepMath-103K-filtered"
    subset: null
    split: "train"

  # ── R1-Style / Thinking ─────────────────────────────────────────
  - id: "open-r1/Mixture-of-Thoughts"
    subset: "all"       # FIX: requires config name — available: all, code, math, science
    split: "train"
  - id: "open-r1/OpenThoughts-114k-math"
    subset: null
    split: "train"
  - id: "open-thoughts/OpenThoughts-114k"
    subset: null
    split: "train"
  - id: "open-thoughts/OpenThoughts2-1M"
    subset: null
    split: "train"
  - id: "ServiceNow-AI/R1-Distill-SFT"
    subset: "v0"        # FIX: requires config name — available: v0, v1
    split: "train"
  - id: "Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B"
    subset: null
    split: "train"
  - id: "bespokelabs/Bespoke-Stratos-17k"
    subset: null
    split: "train"
  - id: "simplescaling/s1K-1.1"
    subset: null
    split: "train"
  - id: "QuixiAI/dolphin-r1"
    subset: null
    split: "train"
  - id: "cognitivecomputations/dolphin-r1"
    subset: "reasoning-deepseek"   # FIX: requires config name — available: nonreasoning, reasoning-deepseek, reasoning-flash
    split: "train"
  - id: "prithivMLmods/Deepthink-Reasoning-Instruction"
    subset: null
    split: "train"
  - id: "EricLu/SCP-116K"
    subset: null
    split: "train"
  - id: "Rickxz06/RAfull"
    subset: null
    split: "train"

  # ── Code Reasoning ──────────────────────────────────────────────
  - id: "nvidia/OpenCodeReasoning"
    subset: "split0"    # FIX: requires config name — available: split0, split1
    split: "train"
  - id: "nvidia/OpenCodeReasoning-2"
    subset: "python"    # FIX: requires config name + split — available splits: python, cpp
    split: "python"
  - id: "mlfoundations-dev/a1_code_opencodereasoning"
    subset: null
    split: "train"
  - id: "efficientscaling/Z1-Code-Reasoning-107K"
    subset: null
    split: "train"
  - id: "open-r1/codeforces-cots"
    subset: null
    split: "train"
  - id: "open-r1/codeforces"
    subset: null
    split: "train"
  - id: "microsoft/rStar-Coder"
    subset: null
    split: "train"
  - id: "PrimeIntellect/SYNTHETIC-1"
    subset: null
    split: "train"

  # ── PRM / Step-Level ────────────────────────────────────────────
  - id: "tasksource/PRM800K"
    subset: null
    split: "train"
  - id: "peiyi9979/Math-Shepherd"
    subset: null
    split: "train"
  - id: "allenai/RLVR-GSM"
    subset: null
    split: "train"
  - id: "allenai/RLVR-MATH"
    subset: null
    split: "train"
